{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#library import\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import utils\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras import models, layers, optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Add, concatenate, Input\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.layers.convolutional import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.set_random_seed(seed)\n",
    "    print('[*]Set seed: {}'.format(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model 평가함수 작성\n",
    "recall + precision 을 이용하여 f1 score 계산\n",
    "model Callback 함수에서 사용\n",
    "'''\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "데이터 수, batch_size를 이용하여 step 계산\n",
    "'''\n",
    "def get_steps(num_samples, batch_size):\n",
    "    if (num_samples % batch_size) > 0:\n",
    "        return (num_samples // batch_size) + 1\n",
    "    else:\n",
    "        return num_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Epoch 종료 시 마다 수행\n",
    "'''\n",
    "def get_callback(model_path, lr, monitor, patient=10, warmup_epoch=5, min_lr=0.00001):\n",
    "    \n",
    "    monitor = 'val_acc' if monitor is 'val_acc' else 'val_f1_m'\n",
    "    direction = 'max' if monitor in ['val_f1_m', 'val_acc'] else 'min'\n",
    "    \n",
    "    callbacks = [\n",
    "        #조기 종료\n",
    "        EarlyStopping(monitor=monitor,\n",
    "                      patience=patient,\n",
    "                      mode=direction,\n",
    "                      verbose=1),\n",
    "        #모델 저장\n",
    "        ModelCheckpoint(filepath=model_path,\n",
    "                        monitor=monitor,\n",
    "                        verbose=1,\n",
    "                        save_best_only=True,\n",
    "                        mode=direction),\n",
    "        #lr decay\n",
    "        ReduceLROnPlateau(monitor = monitor,\n",
    "                          factor = 0.5,\n",
    "                          patience = patient / 4,\n",
    "                          min_lr=min_lr,\n",
    "                          verbose=1,\n",
    "                          mode=direction,\n",
    "                          warmup_epoch=warmup_epoch)\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file and return binary data\n",
    "'''\n",
    "read file -> binary values\n",
    "'''\n",
    "def getBinaryData(filename):\n",
    "\tbinaryValues = []\n",
    "\tfile = open(filename, \"rb\")\n",
    "\tdata = file.read(1)\n",
    "\twhile data != b\"\":\n",
    "\t\ttry:\n",
    "\t\t\tbinaryValues.append(ord(data))\n",
    "\n",
    "\t\texcept TypeError:\n",
    "\t\t\tpass\n",
    "\n",
    "\t\tdata = file.read(1)\n",
    "\n",
    "\treturn binaryValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#byte frequency\n",
    "def balanceByte(filename, table):\n",
    "    \n",
    "    fn = filename.split(\"/\")[-1]\n",
    "    zero = float(table[0])/4096.0\n",
    "    low = float(sum(table[1:31]))/4096.0\n",
    "    ascii = float(sum(table[32:127]))/4096.0\n",
    "    high = float(sum(table[128:254]))/4096.0\n",
    "    ff = float(table[255])/4096.0\n",
    "    return [zero, low, ascii, high, ff]\n",
    "\n",
    "def get_frequency(filename):\n",
    "    table = [0] * 256\n",
    "    data = open(filename, 'rb')\n",
    "    buff = data.read(2 ** 20)\n",
    "    while buff:\n",
    "        for c in buff:\n",
    "            table[c] += 1\n",
    "        buff = data.read(2 ** 20)\n",
    "    data.close()\n",
    "    table.extend(balanceByte(filename, table))\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_path(path_dir):\n",
    "    if not os.path.exists(path_dir):\n",
    "        os.makedirs(path_dir)\n",
    "        print('[*]Make dir: {}'.format(path_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(raw_file, data_dir):\n",
    "    if os.path.exists(data_dir):\n",
    "        return\n",
    "    os.makedirs(data_dir)\n",
    "    print('[*]Make dir: {}'.format(data_dir))\n",
    "    chunk_size = 4096\n",
    "    idx = 0\n",
    "    print('[*]Make bin file')\n",
    "    with open(raw_file, \"rb\") as f:\n",
    "        chunk = f.read(chunk_size)\n",
    "        while chunk:\n",
    "            with open(os.path.join(data_dir, str(idx)), \"wb\") as chunk_file:\n",
    "                chunk_file.write(chunk)\n",
    "            idx += 1\n",
    "            chunk = f.read(chunk_size)\n",
    "            print('>>{0:<10}'.format(idx), end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_byte_cols():\n",
    "    byte_cols = []\n",
    "    for col in range(0, 256):\n",
    "        byte_cols.append(col)\n",
    "    for col in ['0x00', 'low', 'ascii', 'high','0xff']:\n",
    "        byte_cols.append(col)\n",
    "    return byte_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frequency(df, data_dir, byte_cols):\n",
    "    #add frequency col\n",
    "    for col in byte_cols:\n",
    "        df[col] = None\n",
    "    rs = []\n",
    "    for idx in range(0, len(df)):\n",
    "        table = get_frequency(os.path.join(data_dir, df.iloc[idx]['file']))\n",
    "        series = dict(zip(byte_cols, table))\n",
    "        rs.append(series)\n",
    "    df.loc[:, byte_cols] = pd.DataFrame(rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bindata(df, data_dir):\n",
    "    df['data'] = df['file'].map(lambda x: getBinaryData(os.path.join(data_dir, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_type_big(df):\n",
    "    df['type_big'] = df['type'].str.split('-').map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "add binary data\n",
    "standard scaling\n",
    "'''\n",
    "def add_col(df, data_dir):\n",
    "    df = df.copy()\n",
    "    df['file'] = df['file'].astype(str)\n",
    "    #add data column\n",
    "    add_frequency(df, data_dir, byte_cols=get_byte_cols())\n",
    "    add_bindata(df, data_dir)\n",
    "    print('[*]Add col')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_col_target(df):\n",
    "    df = df.copy()\n",
    "    add_type_big(df)\n",
    "    print('[*]Add col target')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scaler(df, scaler):\n",
    "    df = df.copy()\n",
    "    #standard scaler\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype != 'object':\n",
    "            scaler.fit(df[[col]])\n",
    "            df[col] = scaler.transform(df[[col]])\n",
    "    print('[*]Apply Scaler')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN1D(filter_num,filter_size, dim, num_classes, \n",
    "                  activation='relu', maxpool_size=2):\n",
    "    #cnn input\n",
    "    cnn_input = Input(shape=(dim, 1))\n",
    "    #cnn layer\n",
    "    cnn_layer = Conv1D(kernel_size=filter_size,\n",
    "                         filters=filter_num)(cnn_input)\n",
    "    cnn_layer = BatchNormalization()(cnn_layer)\n",
    "    cnn_layer = Activation(activation)(cnn_layer)\n",
    "    cnn_layer = MaxPooling1D(pool_size=(maxpool_size))(cnn_layer)\n",
    "    \n",
    "    cnn_layer = Conv1D(kernel_size=filter_size,\n",
    "                         filters=filter_num)(cnn_layer)\n",
    "    cnn_layer = BatchNormalization()(cnn_layer)\n",
    "    cnn_layer = Activation(activation)(cnn_layer)\n",
    "    cnn_layer = MaxPooling1D(pool_size=(maxpool_size))(cnn_layer)\n",
    "    \n",
    "    cnn_layer = Conv1D(kernel_size=filter_size,\n",
    "                         filters=filter_num)(cnn_layer)\n",
    "    cnn_layer = BatchNormalization()(cnn_layer)\n",
    "    cnn_layer = Activation(activation)(cnn_layer)\n",
    "    cnn_layer = MaxPooling1D(pool_size=(maxpool_size))(cnn_layer)\n",
    "    cnn_layer = Flatten()(cnn_layer)\n",
    "    \n",
    "    #byte input\n",
    "    byte_input = Input(shape=(261,1), name='byte_input')\n",
    "    #byte layer\n",
    "    byte_layer = Flatten()(byte_input)\n",
    "    \n",
    "    merge_layer = concatenate([cnn_layer, byte_layer])\n",
    "    \n",
    "    merge_layer = Dense(256)(merge_layer)\n",
    "    merge_layer = BatchNormalization()(merge_layer)\n",
    "    merge_layer = Activation(activation)(merge_layer)\n",
    "    \n",
    "    merge_layer = Dense(64)(merge_layer)\n",
    "    merge_layer = BatchNormalization()(merge_layer)\n",
    "    merge_layer = Activation(activation)(merge_layer)\n",
    "    \n",
    "    merge_layer = Dense(num_classes)(merge_layer)\n",
    "    merge_layer = Activation('softmax')(merge_layer)\n",
    "    final_model = Model(inputs=[cnn_input, byte_input],\n",
    "                        outputs=merge_layer)\n",
    "    \n",
    "    return final_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data unbalanced -> remove\n",
    "'''\n",
    "def remove_oversample(df, target):\n",
    "    df = df.copy()\n",
    "    min_val = df[target].value_counts().min()\n",
    "    drop_indexes = []\n",
    "    vals = df['type_big'].unique()\n",
    "    for val in vals:\n",
    "        indexes = df[df['type_big']==val].index\n",
    "        if len(indexes) > min_val:\n",
    "            df = df.drop(indexes[min_val:])\n",
    "            drop_indexes.extend(indexes[min_val:])\n",
    "        print('[*]Drop {}: {}->{}'.format(target,\n",
    "                                          len(indexes),\n",
    "                                          min_val))\n",
    "    return df, drop_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "target -> label encoding\n",
    "'''\n",
    "def add_label(df, target, target_label):\n",
    "    df = df.copy()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df[target])\n",
    "    df[target_label] = le.transform(df[target])\n",
    "    print('[*]Add col: {}'.format(target_label))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "split x, y by kfold index\n",
    "'''\n",
    "def get_train_data(df, cnn_col, byte_cols, target, num_class, index, test=False):\n",
    "    \n",
    "    byte_dim = len(byte_cols)\n",
    "    data_dim =len(df['data'][0])\n",
    "    #get all index if test\n",
    "    index = list(range(0, len(df))) if test else index\n",
    "    array_dim = len(index)\n",
    "    \n",
    "    X_train = np.array([df[cnn_col].iloc[index]])\n",
    "    X_train = X_train.reshape((array_dim, data_dim, -1))\n",
    "    \n",
    "    X_train_byte = np.array([df[byte_cols].iloc[index,:].values])\n",
    "    X_train_byte = X_train_byte.reshape((array_dim, len(byte_cols), -1))\n",
    "    \n",
    "    Y_train = None\n",
    "    if not test:\n",
    "        Y_train = np.array([df[target].iloc[index]])\n",
    "        Y_train = utils.to_categorical(Y_train,\n",
    "                                       num_classes=num_class)\n",
    "        Y_train = Y_train.reshape((array_dim, num_class))\n",
    "        \n",
    "    return X_train, X_train_byte, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, opt, skf, train_fold_step,\n",
    "          byte_cols, cnn_col, target, model_dir, monitor):\n",
    "    #check col\n",
    "    if cnn_col not in df.columns:\n",
    "        print('[*]{} is not in colummns'.format(cnn_col))\n",
    "    for col in byte_cols:\n",
    "        if col not in df.columns:\n",
    "            print('[*]{} is not in colummns'.format(col))\n",
    "            \n",
    "    histories = []\n",
    "        \n",
    "    for idx1, filter_num in enumerate(params['test_filter_nums']):\n",
    "        for idx2, filter_size in enumerate(params['test_filter_sizes']):\n",
    "            \n",
    "            for fold_step, (train_index, valid_index) in enumerate(skf.split(df['type_big'], df['type_big'])):\n",
    "                print('=================filter_num: {} / filter_size: {} / fold: {}================='.format(filter_num, \n",
    "                                                                                                             filter_size,\n",
    "                                                                                                             fold_step))\n",
    "                #set model name\n",
    "                #save best model of kfold models\n",
    "                model_name = params['model_name_format'].format(filter_num, filter_size, fold_step)  # save model path\n",
    "                model_path = os.path.join(model_dir, model_name)\n",
    "                #num class\n",
    "                num_class = len(df[target].unique())\n",
    "                #cnn dim\n",
    "                cnn_dim = len(df[cnn_col][0])\n",
    "                #set train\n",
    "                X_train, X_train_byte, Y_train = get_train_data(df, cnn_col, byte_cols,\n",
    "                                                                target, num_class, train_index)\n",
    "                #set test\n",
    "                X_test, X_test_byte, Y_test = get_train_data(df, cnn_col, byte_cols,\n",
    "                                                             target, num_class, valid_index)\n",
    "                #set model\n",
    "                model = CNN1D(filter_num=filter_num, filter_size=filter_size,\n",
    "                              dim=cnn_dim, num_classes=num_class)\n",
    "                model.compile(loss='categorical_crossentropy', optimizer=opt,\n",
    "                              metrics=['accuracy', f1_m])\n",
    "                \n",
    "                #train\n",
    "                history = model.fit([X_train,X_train_byte], Y_train, \n",
    "                                    batch_size=params['batch_size'],\n",
    "                                    epochs=params['epochs'],\n",
    "                                    validation_data=([X_test, X_test_byte], Y_test),\n",
    "                                    shuffle=True,\n",
    "                                    callbacks=get_callback(model_path, params['lr'], monitor),\n",
    "                                    verbose=1)\n",
    "                histories.append(history)\n",
    "\n",
    "                #for train one fold. optional.\n",
    "                if fold_step == train_fold_step-1:\n",
    "                    break\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get history dictionary to dataframe\n",
    "def histories_to_df(histories, target_col, train_fold_step):\n",
    "    history_df = pd.DataFrame()\n",
    "    idx = 0\n",
    "    for idx1, filter_num in enumerate(params['test_filter_nums']):\n",
    "        for idx2, filter_size in enumerate(params['test_filter_sizes']):\n",
    "            for fold in range(0, train_fold_step):\n",
    "                history = histories[idx].history\n",
    "                idx += 1\n",
    "                max_val_idx = history[target_col].index(max(history[target_col]))\n",
    "                temp = {}\n",
    "                for key in history.keys():\n",
    "                    temp[key] = history[key][max_val_idx]\n",
    "                history_df['num_{}_size_{}_fold_{}'.format(filter_num, filter_size, fold)] = pd.Series(temp)\n",
    "    return history_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(df_path, col, col_label, chunksize=1000):\n",
    "    df = None\n",
    "    if not os.path.exists(df_path):\n",
    "        print('[*]File not exists: {}'.format(df_path))\n",
    "        return\n",
    "    \n",
    "    for chunk in pd.read_csv(df_path, chunksize=chunksize):\n",
    "        df = chunk\n",
    "    \n",
    "    if col_label not in df.columns:\n",
    "        print('[*]column not exists in DataFrame: {}'.format(col_label))\n",
    "        return\n",
    "    \n",
    "    classes = df.groupby([col, col_label],as_index=False).size()\n",
    "    classes = classes.sort_values().index\n",
    "    labels = classes.levels[0].values\n",
    "    indexes = classes.levels[1].values\n",
    "    return dict(zip(indexes, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    #fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(model, df, classes):\n",
    "    X_test = X_test_byte = Y_test = None\n",
    "    #get test index from k fold\n",
    "    for fold_step, (train_index, valid_index) in enumerate(skf.split(df['type_big_label'], df['type_big_label'])):\n",
    "        X_test, X_test_byte, Y_test = get_train_data(df,\n",
    "                                                 cnn_col='data',\n",
    "                                                 byte_cols=get_byte_cols(),\n",
    "                                                 target=target_label, \n",
    "                                                 num_class=len(df[target_label].unique()),\n",
    "                                                 index=valid_index)\n",
    "        break\n",
    "    #get y_true\n",
    "    y_true = Y_test\n",
    "    #get y_pred\n",
    "    y_pred = model.predict([X_test, X_test_byte])\n",
    "    \n",
    "    plot_confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1), classes, title='CM')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Set seed: 2\n"
     ]
    }
   ],
   "source": [
    "SEED = 2\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "input_dir = 'input'\n",
    "#model save\n",
    "model_dir = 'models'\n",
    "#raw & meta csv\n",
    "raw_file = os.path.join(input_dir, 'raw_data.raw')\n",
    "csv_file = os.path.join(input_dir, 'base.csv')\n",
    "#binary data folder\n",
    "bin_data_dir = os.path.join(input_dir, 'data_bin')\n",
    "df_fix_path = os.path.join(input_dir, 'data_fix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(raw_file):\n",
    "    print(\"[*]raw file isn's exists({})\".format(raw_file))\n",
    "if not os.path.exists(csv_file):\n",
    "    print(\"[*]csv file isn's exists({})\".format(csv_file))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Make dir: input/data_bin\n",
      "[*]Make bin file\n",
      ">>26400     \r"
     ]
    }
   ],
   "source": [
    "make_path(model_dir)\n",
    "make_data(raw_file, bin_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Add col\n",
      "[*]Apply Scaler\n",
      "[*]Add col target\n",
      "[*]Add col: type_big_label\n",
      "[*]Drop type_big: 8596->5279\n",
      "[*]Drop type_big: 6764->5279\n",
      "[*]Drop type_big: 5761->5279\n",
      "[*]Drop type_big: 5279->5279\n"
     ]
    }
   ],
   "source": [
    "target = 'type_big'#target or target_big\n",
    "target_label = '{}_label'.format(target)\n",
    "\n",
    "df_fix = None\n",
    "remove_sample = True\n",
    "\n",
    "if os.path.exists(df_fix_path):\n",
    "    df_fix = pd.read_csv(df_fix_path)\n",
    "    print('[*]File exists: {}'.format(df_fix_path))\n",
    "else:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df.drop(['offset'], axis=1)\n",
    "    df.columns = ['file', 'type']\n",
    "    df_fix = add_col(df, bin_data_dir)\n",
    "    df_fix = apply_scaler(df_fix, scaler=StandardScaler())\n",
    "    df_fix = add_col_target(df_fix)\n",
    "    df_fix = add_label(df_fix, target, target_label)\n",
    "    df_fix.to_csv(df_fix_path, index=False)\n",
    "    print('[*]Make File: {}'.format(df_fix_path))\n",
    "\n",
    "if remove_sample:\n",
    "    df_fix, _ = remove_oversample(df_fix, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comp     5279\n",
       "image    5279\n",
       "enc      5279\n",
       "video    5279\n",
       "Name: type_big, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix['type_big'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>type</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>0x00</th>\n",
       "      <th>low</th>\n",
       "      <th>ascii</th>\n",
       "      <th>high</th>\n",
       "      <th>0xff</th>\n",
       "      <th>data</th>\n",
       "      <th>type_big</th>\n",
       "      <th>type_big_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>enc-rsa</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00390625</td>\n",
       "      <td>0.11499</td>\n",
       "      <td>0.36084</td>\n",
       "      <td>0.507568</td>\n",
       "      <td>0.00170898</td>\n",
       "      <td>[99, 106, 215, 74, 148, 32, 137, 4, 92, 11, 36...</td>\n",
       "      <td>enc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  file     type   0   1   2   3   4   5   6   7      ...       254 255  \\\n",
       "0    0  enc-rsa  16  10  19  13  22  21  21  16      ...        17   7   \n",
       "\n",
       "         0x00      low    ascii      high        0xff  \\\n",
       "0  0.00390625  0.11499  0.36084  0.507568  0.00170898   \n",
       "\n",
       "                                                data type_big type_big_label  \n",
       "0  [99, 106, 215, 74, 148, 32, 137, 4, 92, 11, 36...      enc              1  \n",
       "\n",
       "[1 rows x 266 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'fold_splits': 10,\n",
    "          'train_fold_num': 1,#1 ~ fold_splits\n",
    "          'batch_size': 64,\n",
    "          'lr': 0.00001,\n",
    "          'epochs': 20,\n",
    "          'test_filter_nums': [4, 8],\n",
    "          'test_filter_sizes': [3, 4],\n",
    "          'model_name_format': 'model_conv1d_baseline_num_{}_size_{}_fold_{}',\n",
    "          'monitor': 'val_acc'#val_acc / val_f1_m\n",
    "         }\n",
    "opt = optimizers.Nadam(lr=params['lr'])  # optimizers\n",
    "skf = StratifiedKFold(n_splits=params['fold_splits'], random_state=SEED)  # StaratifiedKFold -> y label 밸런스 유지하며 k fold 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================filter_num: 4 / filter_size: 3 / fold: 0=================\n",
      "4096 4\n",
      "Train on 19004 samples, validate on 2112 samples\n",
      "Epoch 1/20\n",
      "19004/19004 [==============================] - 7s 346us/step - loss: 1.4253 - acc: 0.3643 - f1_m: 0.3277 - val_loss: 1.2080 - val_acc: 0.4422 - val_f1_m: 0.4115\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.44223, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 2/20\n",
      "19004/19004 [==============================] - 5s 264us/step - loss: 1.1450 - acc: 0.4767 - f1_m: 0.4626 - val_loss: 1.0594 - val_acc: 0.5071 - val_f1_m: 0.4769\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.44223 to 0.50710, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 3/20\n",
      "19004/19004 [==============================] - 5s 268us/step - loss: 1.0168 - acc: 0.5417 - f1_m: 0.5065 - val_loss: 0.9777 - val_acc: 0.5563 - val_f1_m: 0.5023\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.50710 to 0.55634, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 4/20\n",
      "19004/19004 [==============================] - 5s 271us/step - loss: 0.9413 - acc: 0.5751 - f1_m: 0.5207 - val_loss: 0.9227 - val_acc: 0.5857 - val_f1_m: 0.5156\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.55634 to 0.58570, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 5/20\n",
      "19004/19004 [==============================] - 5s 269us/step - loss: 0.8887 - acc: 0.6034 - f1_m: 0.5367 - val_loss: 0.8874 - val_acc: 0.6018 - val_f1_m: 0.5190\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.58570 to 0.60180, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 6/20\n",
      "19004/19004 [==============================] - 5s 272us/step - loss: 0.8480 - acc: 0.6233 - f1_m: 0.5480 - val_loss: 0.8626 - val_acc: 0.6113 - val_f1_m: 0.5224\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.60180 to 0.61127, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 7/20\n",
      "19004/19004 [==============================] - 5s 266us/step - loss: 0.8228 - acc: 0.6323 - f1_m: 0.5537 - val_loss: 0.8414 - val_acc: 0.6217 - val_f1_m: 0.5287\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.61127 to 0.62169, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 8/20\n",
      "19004/19004 [==============================] - 5s 270us/step - loss: 0.7974 - acc: 0.6456 - f1_m: 0.5615 - val_loss: 0.8264 - val_acc: 0.6274 - val_f1_m: 0.5306\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.62169 to 0.62737, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 9/20\n",
      "19004/19004 [==============================] - 5s 264us/step - loss: 0.7779 - acc: 0.6565 - f1_m: 0.5707 - val_loss: 0.8145 - val_acc: 0.6255 - val_f1_m: 0.5332\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.62737\n",
      "Epoch 10/20\n",
      "19004/19004 [==============================] - 5s 267us/step - loss: 0.7602 - acc: 0.6675 - f1_m: 0.5778 - val_loss: 0.8046 - val_acc: 0.6283 - val_f1_m: 0.5354\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.62737 to 0.62831, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 11/20\n",
      "19004/19004 [==============================] - 5s 269us/step - loss: 0.7478 - acc: 0.6757 - f1_m: 0.5845 - val_loss: 0.7960 - val_acc: 0.6330 - val_f1_m: 0.5403\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.62831 to 0.63305, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 12/20\n",
      "19004/19004 [==============================] - 5s 264us/step - loss: 0.7334 - acc: 0.6868 - f1_m: 0.5915 - val_loss: 0.7885 - val_acc: 0.6335 - val_f1_m: 0.5432\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.63305 to 0.63352, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 13/20\n",
      "19004/19004 [==============================] - 5s 275us/step - loss: 0.7194 - acc: 0.6910 - f1_m: 0.6014 - val_loss: 0.7825 - val_acc: 0.6345 - val_f1_m: 0.5459\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.63352 to 0.63447, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 14/20\n",
      "19004/19004 [==============================] - 5s 267us/step - loss: 0.7071 - acc: 0.7013 - f1_m: 0.6118 - val_loss: 0.7777 - val_acc: 0.6330 - val_f1_m: 0.5469\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.63447\n",
      "Epoch 15/20\n",
      "19004/19004 [==============================] - 5s 267us/step - loss: 0.6968 - acc: 0.7075 - f1_m: 0.6187 - val_loss: 0.7735 - val_acc: 0.6330 - val_f1_m: 0.5475\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.63447\n",
      "Epoch 16/20\n",
      "19004/19004 [==============================] - 5s 272us/step - loss: 0.6861 - acc: 0.7129 - f1_m: 0.6291 - val_loss: 0.7698 - val_acc: 0.6330 - val_f1_m: 0.5546\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.63447\n",
      "Epoch 17/20\n",
      "19004/19004 [==============================] - 5s 267us/step - loss: 0.6725 - acc: 0.7230 - f1_m: 0.6408 - val_loss: 0.7672 - val_acc: 0.6316 - val_f1_m: 0.5565\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.63447\n",
      "Epoch 18/20\n",
      "19004/19004 [==============================] - 5s 266us/step - loss: 0.6634 - acc: 0.7315 - f1_m: 0.6510 - val_loss: 0.7649 - val_acc: 0.6330 - val_f1_m: 0.5592\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.63447\n",
      "Epoch 19/20\n",
      "19004/19004 [==============================] - 5s 265us/step - loss: 0.6513 - acc: 0.7404 - f1_m: 0.6614 - val_loss: 0.7631 - val_acc: 0.6359 - val_f1_m: 0.5593\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.63447 to 0.63589, saving model to models/model_conv1d_baseline_num_4_size_3_fold_0\n",
      "Epoch 20/20\n",
      "19004/19004 [==============================] - 5s 267us/step - loss: 0.6394 - acc: 0.7448 - f1_m: 0.6733 - val_loss: 0.7618 - val_acc: 0.6340 - val_f1_m: 0.5609\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.63589\n",
      "=================filter_num: 4 / filter_size: 4 / fold: 0=================\n",
      "4096 4\n",
      "Train on 19004 samples, validate on 2112 samples\n",
      "Epoch 1/20\n",
      "19004/19004 [==============================] - 6s 314us/step - loss: 1.0648 - acc: 0.5270 - f1_m: 0.4453 - val_loss: 0.9197 - val_acc: 0.5942 - val_f1_m: 0.5232\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59422, saving model to models/model_conv1d_baseline_num_4_size_4_fold_0\n",
      "Epoch 2/20\n",
      "19004/19004 [==============================] - 5s 261us/step - loss: 0.8829 - acc: 0.6121 - f1_m: 0.5441 - val_loss: 0.8611 - val_acc: 0.6132 - val_f1_m: 0.5501\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.59422 to 0.61316, saving model to models/model_conv1d_baseline_num_4_size_4_fold_0\n",
      "Epoch 3/20\n",
      "19004/19004 [==============================] - 5s 265us/step - loss: 0.8301 - acc: 0.6338 - f1_m: 0.5671 - val_loss: 0.8334 - val_acc: 0.6245 - val_f1_m: 0.5625\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.61316 to 0.62453, saving model to models/model_conv1d_baseline_num_4_size_4_fold_0\n",
      "Epoch 4/20\n",
      "19004/19004 [==============================] - 5s 267us/step - loss: 0.7948 - acc: 0.6523 - f1_m: 0.5866 - val_loss: 0.8160 - val_acc: 0.6349 - val_f1_m: 0.5633\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.62453 to 0.63494, saving model to models/model_conv1d_baseline_num_4_size_4_fold_0\n",
      "Epoch 5/20\n",
      "19004/19004 [==============================] - 5s 273us/step - loss: 0.7713 - acc: 0.6612 - f1_m: 0.5964 - val_loss: 0.8022 - val_acc: 0.6378 - val_f1_m: 0.5667\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.63494 to 0.63778, saving model to models/model_conv1d_baseline_num_4_size_4_fold_0\n",
      "Epoch 6/20\n",
      "19004/19004 [==============================] - 5s 272us/step - loss: 0.7533 - acc: 0.6695 - f1_m: 0.6066 - val_loss: 0.7926 - val_acc: 0.6364 - val_f1_m: 0.5685\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.63778\n",
      "Epoch 7/20\n",
      "19004/19004 [==============================] - 5s 269us/step - loss: 0.7343 - acc: 0.6825 - f1_m: 0.6165 - val_loss: 0.7844 - val_acc: 0.6359 - val_f1_m: 0.5726\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.63778\n",
      "Epoch 8/20\n",
      "19004/19004 [==============================] - 5s 266us/step - loss: 0.7185 - acc: 0.6876 - f1_m: 0.6272 - val_loss: 0.7782 - val_acc: 0.6373 - val_f1_m: 0.5739\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.63778\n",
      "Epoch 9/20\n",
      "19004/19004 [==============================] - 5s 273us/step - loss: 0.7037 - acc: 0.7013 - f1_m: 0.6362 - val_loss: 0.7723 - val_acc: 0.6392 - val_f1_m: 0.5777\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.63778 to 0.63920, saving model to models/model_conv1d_baseline_num_4_size_4_fold_0\n",
      "Epoch 10/20\n",
      "19004/19004 [==============================] - 5s 272us/step - loss: 0.6906 - acc: 0.7073 - f1_m: 0.6473 - val_loss: 0.7680 - val_acc: 0.6425 - val_f1_m: 0.5792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_acc improved from 0.63920 to 0.64252, saving model to models/model_conv1d_baseline_num_4_size_4_fold_0\n",
      "Epoch 11/20\n",
      "19004/19004 [==============================] - 5s 270us/step - loss: 0.6759 - acc: 0.7158 - f1_m: 0.6560 - val_loss: 0.7648 - val_acc: 0.6439 - val_f1_m: 0.5833\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.64252 to 0.64394, saving model to models/model_conv1d_baseline_num_4_size_4_fold_0\n",
      "Epoch 12/20\n",
      "19004/19004 [==============================] - 5s 265us/step - loss: 0.6659 - acc: 0.7237 - f1_m: 0.6648 - val_loss: 0.7618 - val_acc: 0.6425 - val_f1_m: 0.5821\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.64394\n",
      "Epoch 13/20\n",
      "19004/19004 [==============================] - 5s 267us/step - loss: 0.6524 - acc: 0.7323 - f1_m: 0.6733 - val_loss: 0.7592 - val_acc: 0.6411 - val_f1_m: 0.5857\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.64394\n",
      "Epoch 14/20\n",
      "19004/19004 [==============================] - 5s 267us/step - loss: 0.6393 - acc: 0.7397 - f1_m: 0.6834 - val_loss: 0.7576 - val_acc: 0.6397 - val_f1_m: 0.5881\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.64394\n",
      "Epoch 15/20\n",
      "19004/19004 [==============================] - 5s 263us/step - loss: 0.6275 - acc: 0.7476 - f1_m: 0.6928 - val_loss: 0.7559 - val_acc: 0.6392 - val_f1_m: 0.5890\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.64394\n",
      "Epoch 16/20\n",
      "19004/19004 [==============================] - 5s 264us/step - loss: 0.6177 - acc: 0.7549 - f1_m: 0.7006 - val_loss: 0.7553 - val_acc: 0.6368 - val_f1_m: 0.5916\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.64394\n",
      "Epoch 17/20\n",
      "19004/19004 [==============================] - 5s 269us/step - loss: 0.6060 - acc: 0.7626 - f1_m: 0.7118 - val_loss: 0.7546 - val_acc: 0.6392 - val_f1_m: 0.5926\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.64394\n",
      "Epoch 18/20\n",
      "19004/19004 [==============================] - 5s 271us/step - loss: 0.5966 - acc: 0.7683 - f1_m: 0.7180 - val_loss: 0.7545 - val_acc: 0.6416 - val_f1_m: 0.5940\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.64394\n",
      "Epoch 19/20\n",
      "19004/19004 [==============================] - 5s 276us/step - loss: 0.5832 - acc: 0.7782 - f1_m: 0.7316 - val_loss: 0.7545 - val_acc: 0.6402 - val_f1_m: 0.5944\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.64394\n",
      "Epoch 20/20\n",
      "19004/19004 [==============================] - 5s 266us/step - loss: 0.5727 - acc: 0.7830 - f1_m: 0.7409 - val_loss: 0.7550 - val_acc: 0.6373 - val_f1_m: 0.5941\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.64394\n",
      "=================filter_num: 8 / filter_size: 3 / fold: 0=================\n",
      "4096 4\n",
      "Train on 19004 samples, validate on 2112 samples\n",
      "Epoch 1/20\n",
      "19004/19004 [==============================] - 7s 360us/step - loss: 1.0232 - acc: 0.5463 - f1_m: 0.4743 - val_loss: 0.8903 - val_acc: 0.5956 - val_f1_m: 0.5322\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59564, saving model to models/model_conv1d_baseline_num_8_size_3_fold_0\n",
      "Epoch 2/20\n",
      "19004/19004 [==============================] - 6s 302us/step - loss: 0.8218 - acc: 0.6351 - f1_m: 0.5676 - val_loss: 0.8425 - val_acc: 0.6155 - val_f1_m: 0.5453\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.59564 to 0.61553, saving model to models/model_conv1d_baseline_num_8_size_3_fold_0\n",
      "Epoch 3/20\n",
      "19004/19004 [==============================] - 6s 302us/step - loss: 0.7689 - acc: 0.6630 - f1_m: 0.5964 - val_loss: 0.8195 - val_acc: 0.6127 - val_f1_m: 0.5531\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.61553\n",
      "Epoch 4/20\n",
      "19004/19004 [==============================] - 6s 306us/step - loss: 0.7298 - acc: 0.6880 - f1_m: 0.6181 - val_loss: 0.8060 - val_acc: 0.6108 - val_f1_m: 0.5546\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.61553\n",
      "Epoch 5/20\n",
      "19004/19004 [==============================] - 6s 299us/step - loss: 0.7024 - acc: 0.7078 - f1_m: 0.6354 - val_loss: 0.7961 - val_acc: 0.6141 - val_f1_m: 0.5599\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.61553\n",
      "Epoch 6/20\n",
      "19004/19004 [==============================] - 6s 307us/step - loss: 0.6785 - acc: 0.7246 - f1_m: 0.6545 - val_loss: 0.7903 - val_acc: 0.6198 - val_f1_m: 0.5607\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.61553 to 0.61979, saving model to models/model_conv1d_baseline_num_8_size_3_fold_0\n",
      "Epoch 7/20\n",
      "19004/19004 [==============================] - 6s 305us/step - loss: 0.6554 - acc: 0.7401 - f1_m: 0.6723 - val_loss: 0.7856 - val_acc: 0.6231 - val_f1_m: 0.5638\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.61979 to 0.62311, saving model to models/model_conv1d_baseline_num_8_size_3_fold_0\n",
      "Epoch 8/20\n",
      "19004/19004 [==============================] - 6s 310us/step - loss: 0.6364 - acc: 0.7523 - f1_m: 0.6862 - val_loss: 0.7818 - val_acc: 0.6264 - val_f1_m: 0.5691\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.62311 to 0.62642, saving model to models/model_conv1d_baseline_num_8_size_3_fold_0\n",
      "Epoch 9/20\n",
      "19004/19004 [==============================] - 6s 307us/step - loss: 0.6154 - acc: 0.7690 - f1_m: 0.7075 - val_loss: 0.7802 - val_acc: 0.6312 - val_f1_m: 0.5716\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.62642 to 0.63116, saving model to models/model_conv1d_baseline_num_8_size_3_fold_0\n",
      "Epoch 10/20\n",
      "19004/19004 [==============================] - 6s 310us/step - loss: 0.5984 - acc: 0.7797 - f1_m: 0.7218 - val_loss: 0.7789 - val_acc: 0.6340 - val_f1_m: 0.5727\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.63116 to 0.63400, saving model to models/model_conv1d_baseline_num_8_size_3_fold_0\n",
      "Epoch 11/20\n",
      "19004/19004 [==============================] - 6s 318us/step - loss: 0.5765 - acc: 0.7967 - f1_m: 0.7380 - val_loss: 0.7782 - val_acc: 0.6359 - val_f1_m: 0.5738\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.63400 to 0.63589, saving model to models/model_conv1d_baseline_num_8_size_3_fold_0\n",
      "Epoch 12/20\n",
      "19004/19004 [==============================] - 6s 303us/step - loss: 0.5573 - acc: 0.8085 - f1_m: 0.7558 - val_loss: 0.7786 - val_acc: 0.6302 - val_f1_m: 0.5775\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.63589\n",
      "Epoch 13/20\n",
      "19004/19004 [==============================] - 6s 308us/step - loss: 0.5375 - acc: 0.8254 - f1_m: 0.7729 - val_loss: 0.7800 - val_acc: 0.6326 - val_f1_m: 0.5787\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.63589\n",
      "Epoch 14/20\n",
      "19004/19004 [==============================] - 6s 306us/step - loss: 0.5185 - acc: 0.8360 - f1_m: 0.7864 - val_loss: 0.7810 - val_acc: 0.6297 - val_f1_m: 0.5801\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.63589\n",
      "Epoch 15/20\n",
      "19004/19004 [==============================] - 6s 304us/step - loss: 0.4999 - acc: 0.8478 - f1_m: 0.8025 - val_loss: 0.7837 - val_acc: 0.6293 - val_f1_m: 0.5811\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.63589\n",
      "Epoch 16/20\n",
      "19004/19004 [==============================] - 6s 306us/step - loss: 0.4815 - acc: 0.8596 - f1_m: 0.8161 - val_loss: 0.7857 - val_acc: 0.6293 - val_f1_m: 0.5788\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.63589\n",
      "Epoch 17/20\n",
      "19004/19004 [==============================] - 6s 300us/step - loss: 0.4642 - acc: 0.8702 - f1_m: 0.8304 - val_loss: 0.7887 - val_acc: 0.6293 - val_f1_m: 0.5812\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.63589\n",
      "Epoch 18/20\n",
      "19004/19004 [==============================] - 6s 308us/step - loss: 0.4443 - acc: 0.8821 - f1_m: 0.8455 - val_loss: 0.7919 - val_acc: 0.6283 - val_f1_m: 0.5846\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.63589\n",
      "Epoch 19/20\n",
      "19004/19004 [==============================] - 6s 305us/step - loss: 0.4255 - acc: 0.8941 - f1_m: 0.8582 - val_loss: 0.7953 - val_acc: 0.6259 - val_f1_m: 0.5882\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.63589\n",
      "Epoch 20/20\n",
      "19004/19004 [==============================] - 6s 301us/step - loss: 0.4102 - acc: 0.9016 - f1_m: 0.8679 - val_loss: 0.7993 - val_acc: 0.6236 - val_f1_m: 0.5887\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.63589\n",
      "=================filter_num: 8 / filter_size: 4 / fold: 0=================\n",
      "4096 4\n",
      "Train on 19004 samples, validate on 2112 samples\n",
      "Epoch 1/20\n",
      "19004/19004 [==============================] - 7s 371us/step - loss: 1.0453 - acc: 0.5386 - f1_m: 0.4691 - val_loss: 0.9000 - val_acc: 0.5961 - val_f1_m: 0.5230\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59612, saving model to models/model_conv1d_baseline_num_8_size_4_fold_0\n",
      "Epoch 2/20\n",
      "19004/19004 [==============================] - 6s 310us/step - loss: 0.8359 - acc: 0.6322 - f1_m: 0.5665 - val_loss: 0.8454 - val_acc: 0.6065 - val_f1_m: 0.5479\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.59612 to 0.60653, saving model to models/model_conv1d_baseline_num_8_size_4_fold_0\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19004/19004 [==============================] - 6s 302us/step - loss: 0.7733 - acc: 0.6659 - f1_m: 0.5973 - val_loss: 0.8212 - val_acc: 0.6170 - val_f1_m: 0.5549\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.60653 to 0.61695, saving model to models/model_conv1d_baseline_num_8_size_4_fold_0\n",
      "Epoch 4/20\n",
      "19004/19004 [==============================] - 6s 301us/step - loss: 0.7369 - acc: 0.6810 - f1_m: 0.6191 - val_loss: 0.8061 - val_acc: 0.6203 - val_f1_m: 0.5590\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.61695 to 0.62027, saving model to models/model_conv1d_baseline_num_8_size_4_fold_0\n",
      "Epoch 5/20\n",
      "19004/19004 [==============================] - 6s 299us/step - loss: 0.7079 - acc: 0.6998 - f1_m: 0.6319 - val_loss: 0.7970 - val_acc: 0.6170 - val_f1_m: 0.5618\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.62027\n",
      "Epoch 6/20\n",
      "19004/19004 [==============================] - 6s 302us/step - loss: 0.6842 - acc: 0.7148 - f1_m: 0.6495 - val_loss: 0.7897 - val_acc: 0.6170 - val_f1_m: 0.5644\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.62027\n",
      "Epoch 7/20\n",
      "19004/19004 [==============================] - 6s 299us/step - loss: 0.6606 - acc: 0.7314 - f1_m: 0.6647 - val_loss: 0.7854 - val_acc: 0.6184 - val_f1_m: 0.5687\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.62027\n",
      "Epoch 8/20\n",
      "19004/19004 [==============================] - 6s 303us/step - loss: 0.6402 - acc: 0.7471 - f1_m: 0.6839 - val_loss: 0.7811 - val_acc: 0.6212 - val_f1_m: 0.5727\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.62027 to 0.62121, saving model to models/model_conv1d_baseline_num_8_size_4_fold_0\n",
      "Epoch 9/20\n",
      "19004/19004 [==============================] - 6s 302us/step - loss: 0.6194 - acc: 0.7596 - f1_m: 0.6971 - val_loss: 0.7786 - val_acc: 0.6212 - val_f1_m: 0.5751\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.62121\n",
      "Epoch 10/20\n",
      "19004/19004 [==============================] - 6s 308us/step - loss: 0.6002 - acc: 0.7753 - f1_m: 0.7138 - val_loss: 0.7773 - val_acc: 0.6217 - val_f1_m: 0.5782\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.62121 to 0.62169, saving model to models/model_conv1d_baseline_num_8_size_4_fold_0\n",
      "Epoch 11/20\n",
      "19004/19004 [==============================] - 6s 305us/step - loss: 0.5800 - acc: 0.7927 - f1_m: 0.7289 - val_loss: 0.7764 - val_acc: 0.6236 - val_f1_m: 0.5808\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.62169 to 0.62358, saving model to models/model_conv1d_baseline_num_8_size_4_fold_0\n",
      "Epoch 12/20\n",
      "19004/19004 [==============================] - 6s 304us/step - loss: 0.5623 - acc: 0.8024 - f1_m: 0.7469 - val_loss: 0.7767 - val_acc: 0.6236 - val_f1_m: 0.5828\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.62358\n",
      "Epoch 13/20\n",
      "19004/19004 [==============================] - 6s 303us/step - loss: 0.5408 - acc: 0.8175 - f1_m: 0.7597 - val_loss: 0.7767 - val_acc: 0.6217 - val_f1_m: 0.5849\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.62358\n",
      "Epoch 14/20\n",
      "19004/19004 [==============================] - 6s 310us/step - loss: 0.5257 - acc: 0.8266 - f1_m: 0.7763 - val_loss: 0.7776 - val_acc: 0.6207 - val_f1_m: 0.5870\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.62358\n",
      "Epoch 15/20\n",
      "19004/19004 [==============================] - 6s 307us/step - loss: 0.5048 - acc: 0.8417 - f1_m: 0.7932 - val_loss: 0.7790 - val_acc: 0.6212 - val_f1_m: 0.5885\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.62358\n",
      "Epoch 16/20\n",
      "19004/19004 [==============================] - 6s 308us/step - loss: 0.4857 - acc: 0.8564 - f1_m: 0.8107 - val_loss: 0.7813 - val_acc: 0.6212 - val_f1_m: 0.5904\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.62358\n",
      "Epoch 17/20\n",
      "19004/19004 [==============================] - 6s 304us/step - loss: 0.4681 - acc: 0.8650 - f1_m: 0.8231 - val_loss: 0.7827 - val_acc: 0.6226 - val_f1_m: 0.5927\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.62358\n",
      "Epoch 18/20\n",
      "19004/19004 [==============================] - 6s 312us/step - loss: 0.4494 - acc: 0.8788 - f1_m: 0.8361 - val_loss: 0.7847 - val_acc: 0.6226 - val_f1_m: 0.5920\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.62358\n",
      "Epoch 19/20\n",
      "19004/19004 [==============================] - 6s 308us/step - loss: 0.4336 - acc: 0.8860 - f1_m: 0.8495 - val_loss: 0.7884 - val_acc: 0.6212 - val_f1_m: 0.5944\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.62358\n",
      "Epoch 20/20\n",
      "19004/19004 [==============================] - 6s 306us/step - loss: 0.4161 - acc: 0.8977 - f1_m: 0.8635 - val_loss: 0.7909 - val_acc: 0.6226 - val_f1_m: 0.5982\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.62358\n"
     ]
    }
   ],
   "source": [
    "histories = train(df=df_fix,\n",
    "                  opt=opt,\n",
    "                  skf=skf,\n",
    "                  train_fold_step=params['train_fold_num'],\n",
    "                  byte_cols=get_byte_cols(),\n",
    "                  cnn_col='data',\n",
    "                  target=target_label,\n",
    "                  model_dir=model_dir,\n",
    "                  monitor=params['monitor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1_m</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_f1_m</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_4_size_3_fold_0</th>\n",
       "      <td>0.740423</td>\n",
       "      <td>0.661444</td>\n",
       "      <td>0.651312</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.635890</td>\n",
       "      <td>0.559313</td>\n",
       "      <td>0.763051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_4_size_4_fold_0</th>\n",
       "      <td>0.715797</td>\n",
       "      <td>0.655983</td>\n",
       "      <td>0.675920</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.643939</td>\n",
       "      <td>0.583322</td>\n",
       "      <td>0.764845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_8_size_3_fold_0</th>\n",
       "      <td>0.796727</td>\n",
       "      <td>0.737985</td>\n",
       "      <td>0.576529</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.635890</td>\n",
       "      <td>0.573842</td>\n",
       "      <td>0.778155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_8_size_4_fold_0</th>\n",
       "      <td>0.792728</td>\n",
       "      <td>0.728939</td>\n",
       "      <td>0.579968</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.623580</td>\n",
       "      <td>0.580837</td>\n",
       "      <td>0.776386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          acc      f1_m      loss       lr   val_acc  \\\n",
       "num_4_size_3_fold_0  0.740423  0.661444  0.651312  0.00001  0.635890   \n",
       "num_4_size_4_fold_0  0.715797  0.655983  0.675920  0.00001  0.643939   \n",
       "num_8_size_3_fold_0  0.796727  0.737985  0.576529  0.00001  0.635890   \n",
       "num_8_size_4_fold_0  0.792728  0.728939  0.579968  0.00001  0.623580   \n",
       "\n",
       "                     val_f1_m  val_loss  \n",
       "num_4_size_3_fold_0  0.559313  0.763051  \n",
       "num_4_size_4_fold_0  0.583322  0.764845  \n",
       "num_8_size_3_fold_0  0.573842  0.778155  \n",
       "num_8_size_4_fold_0  0.580837  0.776386  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = histories_to_df(histories,\n",
    "                             target_col=params['monitor'],\n",
    "                             train_fold_step=params['train_fold_num'])\n",
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1_m</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_f1_m</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_4_size_4_fold_0</th>\n",
       "      <td>0.715797</td>\n",
       "      <td>0.655983</td>\n",
       "      <td>0.67592</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.643939</td>\n",
       "      <td>0.583322</td>\n",
       "      <td>0.764845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          acc      f1_m     loss       lr   val_acc  val_f1_m  \\\n",
       "num_4_size_4_fold_0  0.715797  0.655983  0.67592  0.00001  0.643939  0.583322   \n",
       "\n",
       "                     val_loss  \n",
       "num_4_size_4_fold_0  0.764845  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc = history_df.loc[history_df[params['monitor']].idxmax()]\n",
    "best_num, best_size, best_fold = [int(x) for x in re.compile('([+\\d])').findall(best_acc.name)]\n",
    "pd.DataFrame(best_acc).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model/weight\n",
    "model = CNN1D(filter_num=best_num,\n",
    "              filter_size=best_size,\n",
    "              dim=len(df_fix['data'][0]),\n",
    "              num_classes=len(df_fix[target_label].unique()))\n",
    "\n",
    "model_name = params['model_name_format'].format(best_num,\n",
    "                                                best_size,\n",
    "                                                best_fold)\n",
    "weight_path = os.path.join(model_dir, model_name)\n",
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[330 101   2  95]\n",
      " [ 23 275   0 230]\n",
      " [  9  18 488  13]\n",
      " [ 27 233   1 267]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "#get test index from train data with kfold\n",
    "# get class name\n",
    "classes = get_class_name(df_fix_path, target, target_label, chunksize=1000)\n",
    "plot_cm(model, df_fix, classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(raw_file_test, bin_test_dir,\n",
    "         num, size, fold, target='type_big'):\n",
    "    make_data(raw_file_test, bin_test_dir)# make bin file\n",
    "    target_label = '{}_label'.format(target)\n",
    "\n",
    "    #test df\n",
    "    df_test = pd.DataFrame({'file': os.listdir(bin_test_dir)})#make dataframe\n",
    "    print('[*]Test {} samples'.format(len(df_test)))\n",
    "    df_test_fix = add_col(df_test, bin_data_dir)  # fix dataframe\n",
    "    df_test_fix = apply_scaler(df_test_fix, scaler=StandardScaler())  # apply scaler\n",
    "\n",
    "    #get class labels from df _fix.csv\n",
    "    df_fix_path = os.path.join(input_dir, 'data_fix.csv')\n",
    "    classes = get_class_name(df_fix_path, target, target_label, chunksize=1000)\n",
    "\n",
    "    #load model/weight\n",
    "    model = CNN1D(filter_num=num,\n",
    "                  filter_size=size,\n",
    "                  dim=len(df_test_fix['data'][0]),\n",
    "                  num_classes=len(classes))\n",
    "\n",
    "    model_name = params['model_name_format'].format(num,\n",
    "                                                    size,\n",
    "                                                    fold)\n",
    "    weight_path = os.path.join(model_dir, model_name)\n",
    "    model.load_weights(weight_path)\n",
    "\n",
    "    #get input\n",
    "    X_test, X_test_byte, _ = get_train_data(df_test_fix,\n",
    "                                             cnn_col='data',\n",
    "                                             byte_cols=get_byte_cols(),\n",
    "                                             target=None, \n",
    "                                             num_class=len(classes),\n",
    "                                             index=None,\n",
    "                                             test=True)\n",
    "    y_pred = model.predict([X_test, X_test_byte]).argmax(axis=1)\n",
    "    y_pred_label = [classes[pred] for pred in y_pred]\n",
    "    df_test.loc[:, target] = y_pred_label\n",
    "    return df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Test 26400 samples\n",
      "[*]Add col\n",
      "[*]Apply Scaler\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>type_big</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18648</td>\n",
       "      <td>comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3846</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25963</td>\n",
       "      <td>comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6722</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21964</td>\n",
       "      <td>image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12565</td>\n",
       "      <td>comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20362</td>\n",
       "      <td>enc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3804</td>\n",
       "      <td>image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16148</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1788</td>\n",
       "      <td>image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4771</td>\n",
       "      <td>image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15088</td>\n",
       "      <td>enc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16426</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18181</td>\n",
       "      <td>image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>70</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10557</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17701</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5736</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5940</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24695</td>\n",
       "      <td>enc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file type_big\n",
       "0   18648     comp\n",
       "1    3846    video\n",
       "2   25963     comp\n",
       "3    6722    video\n",
       "4   21964    image\n",
       "5   12565     comp\n",
       "6   20362      enc\n",
       "7    3804    image\n",
       "8   16148    video\n",
       "9    1788    image\n",
       "10   4771    image\n",
       "11  15088      enc\n",
       "12  16426    video\n",
       "13  18181    image\n",
       "14     70    video\n",
       "15  10557    video\n",
       "16  17701    video\n",
       "17   5736    video\n",
       "18   5940    video\n",
       "19  24695      enc"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test file\n",
    "raw_file_test = os.path.join(input_dir, 'raw_data.raw') #raw file path\n",
    "bin_test_dir = os.path.join(input_dir, 'test_bin') # save bin file path\n",
    "df_test = test(raw_file_test, bin_test_dir,\n",
    "               num=best_num, size=best_size, fold=best_fold)\n",
    "df_test.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
